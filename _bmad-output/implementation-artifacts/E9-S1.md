# Story 9.1: Implement Whisper STT Service

**Epic:** E9 - Voice Agent (POST-MVP)  
**Status:** post-mvp  
**Priority:** P2  
**Dependencies:** API key (OPENAI_API_KEY)  
**Blocks:** 9.3

## Story

As a developer,
I want a speech-to-text service using OpenAI Whisper,
so that users can speak their profile information.

## Acceptance Criteria

1. **Given** an audio recording
   **When** I call transcribeAudio()
   **Then** I get the text transcription

2. **Given** various audio formats (webm, mp3, wav)
   **When** I call transcribeAudio()
   **Then** all formats are supported

3. **Given** API errors
   **When** transcription fails
   **Then** errors are handled gracefully

## Tasks / Subtasks

- [ ] Task 1: Create Whisper client
  - [ ] Create `src/lib/voice/whisper.ts`
  - [ ] Use OpenAI API for Whisper
  - [ ] Support multiple audio formats

- [ ] Task 2: Create API route
  - [ ] Create POST /api/voice/transcribe
  - [ ] Accept audio file upload
  - [ ] Return transcription

- [ ] Task 3: Add error handling
  - [ ] Handle file size limits
  - [ ] Handle API errors
  - [ ] Log for debugging

## Dev Notes

- Whisper is part of OpenAI API
- Max file size: 25MB
- Consider chunking for longer recordings

### Code Structure

```typescript
// src/lib/voice/whisper.ts
export async function transcribeAudio(
  audioFile: File | Blob
): Promise<string>
```

### References

- [Source: planning-artifacts/architecture.md#Voice Integration]
- OpenAI Whisper API documentation

## Dev Agent Record

### Agent Model Used

### Debug Log References

### Completion Notes List

### File List
